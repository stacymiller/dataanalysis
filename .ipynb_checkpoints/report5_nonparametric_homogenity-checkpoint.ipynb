{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Критерии однородности для независимых выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Точный и асимптотический критерий Вилкоксона\n",
    "Применяется при сравнении двух выборок для непараметрической проверки гипотезы о равенстве средних в этих выборках.\n",
    "\n",
    "*Точный критерий Вилкоксона* применяется к двум выборкам размера $n_1$ и $n_2$ соответственно. Предположение о равенстве средних заменяется эксвивалентным о равенстве числа инверсий $u$ и контринверсий $v$, т.е. $H_0: u = v$, $H_1: u > v$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем данные для демонстрации точного критерия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        val  group\n",
      "0  0.191740      1\n",
      "1  2.257171      1\n",
      "2  2.359265      1\n",
      "3  1.812955      1\n",
      "4  2.845002      1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, rankdata\n",
    "# import matplotlib.pyplot as plt\n",
    "# from numpy.linalg import eig\n",
    "# data = pd.read_table(\"wilcoxon.csv\", decimal=\",\", sep=\";\", usecols=[0,1,2,4])\n",
    "\n",
    "n1 = 20\n",
    "n2 = 26\n",
    "d1 = norm(1,2).rvs(n1)  # random normal sample with mean = 1 and sd = 2\n",
    "d2 = norm(1,2).rvs(n2)  # random normal sample with mean = 1 and sd = 2\n",
    "data1 = pd.DataFrame()\n",
    "data1[\"val\"] = d1\n",
    "data1[\"group\"] = 1\n",
    "data2 = pd.DataFrame()\n",
    "data2[\"val\"] = d2\n",
    "data2[\"group\"] = 2\n",
    "data = data1.append(data2)\n",
    "del data1, data2\n",
    "print data.head()  # shows first rows from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точный критерий Вилкоксона подсчитывает число инверсий в данных и сравнивает его с критическим для данного объёма выборки числом инверсий.\n",
    "*Инверсией* множеств $X$ и $Y$ (с заданным общим для них обоих линейным упорядочением) называется такая пара $x\\in X, y\\in Y$,  для которой $x > y$ (*контринверсия* -- $y > x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "число инверсий в данных: 310\n",
      "объём данных: 46\n"
     ]
    }
   ],
   "source": [
    "# group: group to count inversions against\n",
    "def count_inversions(data, group):\n",
    "    sorteddata = data.sort(\"val\")\n",
    "    selector = sorteddata[\"group\"] == group\n",
    "    this = sorteddata[selector]  # elements of group, index saved from original dataset\n",
    "    other = sorteddata[np.logical_not(selector)]  # elements of other group, same as above\n",
    "    inv_count = 0\n",
    "    for (this_index, u) in this.iterrows():\n",
    "        inv_count += len(other[other.index > this_index])  # # of elements \n",
    "                                      # that appeared after and were greater than this one\n",
    "    return inv_count\n",
    "\n",
    "print \"число инверсий в данных: \" + str(count_inversions(data, 1))\n",
    "print \"объём данных: \" + str(n1+ n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея таблицу распределения Вилкоксона (насколько близко к предельно допустимому для такого объёма данных находится данное число инверсий), по числу инверсий можно понять, отвергать или не отвергать гипотезу $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пользоваться таблицей неудобно, поэтому существует асимптотический критерий Вилкоксона (*критерий Манна-Уитни*). Так как известны математическое ожидание и дисперсия числа инверсий, мы можем (выразив для удобства число инверсий через сумму рангов $R$: $r_i$ -- число инверсий второй выборки с i-м элементом первой, $u = \\sum_{i=1}^{n_1}(r_i - i) = R - \\frac{n_1(n_1 + 1)}{2}$) воспользоваться центральной предельной теоремой и использовать асимптотическую статистику $$t = \\frac{R - \\frac{n_1(n_1 + 1)}{2} - \\frac{n_1n_2}{2}}{\\sqrt{\\frac{n_1n_2(n_1+n_2+1)}{12}}} \\sim N(0,1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доверительный интервал: (-1.959964, 1.959964)\n",
      "значение статистики: 0.354593765742\n"
     ]
    }
   ],
   "source": [
    "data[\"rank\"] = rankdata(data.val)  # ranks of data.val are now in data.rank\n",
    "R = data[data.group == 1][\"rank\"].sum()\n",
    "t = (R - n1*(n1 + 1)/2 - n1*n2/2) / np.sqrt(n1*n2*(n1 + n2 + 1)/12)\n",
    "critical_value = norm(0,1).ppf(0.975)  # .975 quantile of normal distribution\n",
    "print \"доверительный интервал: (%f, %f)\"%(-critical_value, critical_value)\n",
    "print \"значение статистики:\", t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартная реализация этого теста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0.354535726006\n",
      "p-value =  0.722937434989\n"
     ]
    }
   ],
   "source": [
    "t, pvalue = sp.stats.ranksums(data[data.group == 1].val, data[data.group == 2].val)\n",
    "print \"t =\", t\n",
    "print \"p-value = \", pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для наших случайных данных мы получили p-value 0.72, т.е. для всех стандартных уровней значимости гипотеза о равенстве средних в выборках не отвергается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Критерии однородности для зависимых выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "n = 50\n",
    "data[\"t1\"] = norm(1,2).rvs(n)\n",
    "data[\"t2\"] = data[\"t1\"]*2 + norm(0,2).rvs(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация данных\n",
    "`data[\"t1\"]` -- значения некоторой величины в $n$ экспериментах в момент времени $t_1$, `data[\"t2\"]` -- значения той же величины в тех же экспериментах в момент времени $t_2$. По значениям этой величины можно сделать вывод $r_i\\left(x_{t_1}, x_{t_2}\\right)$ об успехе или неудаче $i$-го эксперимента. О <<направленности>> результата говорит знак $r_i\\left(x_{t_1}, x_{t_2}\\right)$: $<0$ в случае неудачи, $0$ в случае отсутствия результата, $>0$ в случае успешного исхода, абсолютное значение $r_i\\left(x_{t_1}, x_{t_2}\\right)$ несёт информацию о степени эффективности результата. Эффективность для различных $i$ должна быть сравнима."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В демонстрации будем использовать $\\forall i\\in 1:n\\;\\; r_i\\left(x_{t_1}, x_{t_2}\\right) = x_{t_2} - x_{t_1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знаковый критерий Вилкоксона\n",
    "Используется для оценки значимости различий между парными наблюдениями (применим для анализа повторных наблюдений, сравнения разультатов экспериментов с различными параметрами).\n",
    "\n",
    "Необходимые предположения:\n",
    "- результаты измерений должны быть хотя бы численными (чтобы иметь возможность сравнить размер различий для нескольких пар наблюдений)\n",
    "- каждая пара наблюдений выбирается случайно и независимо, все данные имеют одно и то же распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведём пример использования знакового критерия Вилкоксона в реальной ситуации.\n",
    "\n",
    "Необходимо выбрать метрику похожести изображений, которая бы наиболее точно различала похожие кадры. По этой метрике для последовательности кадров в видеофайле с искажёнными (размытыми, уменьшенными или увеличенными) и удалёнными кадрами подбираются соответствующие кадры в исходном видеофайле, тем самым восстанавливается оригинальная нумерация кадров в видеофайле. Для разных способов искажения изображения была оценена вероятность ошибки алгоритма синхронизации с использованием двух различных метрик похожести, результаты приведены ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PSNR  Pearson\n",
      "0  0.74     0.71\n",
      "1  0.50     0.57\n",
      "2  0.75     0.78\n",
      "3  1.05     1.06\n",
      "4  1.43     1.19\n",
      "5  0.81     0.81\n",
      "6  0.73     0.61\n",
      "7  0.50     0.49\n"
     ]
    }
   ],
   "source": [
    "PSNR = [0.74, 0.5, 0.75, 1.05, 1.43, 0.81, 0.73, 0.5]\n",
    "Pearson = [0.71, 0.57, 0.78, 1.06, 1.19, 0.81, 0.61, 0.49]\n",
    "test_sample = pd.DataFrame({\"PSNR\": PSNR, \"Pearson\": Pearson})\n",
    "print test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хочется определить, значимы ли различия в вероятностях ошибок и стоит ли предпочесть одну метрику другой. Выдвигаются гипотезы:\n",
    "$$H_0: \\text{ средняя разность между парами наблюдений равна } 0$$\n",
    "$$H_1: \\text{ средняя разность между парами наблюдений отлична от } 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть выборка состоит из набора измерений $\\left\\lbrace(x_i, y_i)\\right\\rbrace_{i=1}^n$. Тогда $\\forall i \\in 1:n \\;\\;\\exists s_i = \\mathrm{sgn}(x_i - y_i), v_i = \\left|x_i - y_i\\right|$. Уберём из выборки наблюдения, у которых $v_i = 0$ (они не могут повлиять на наше решение за исключением, возможно, тех случаев, когда таких наблюдений большинство). У оставшихся наблюдений (обозначим множество их индексов $N_r$) проранжируем $v_i$ (присваивая одинаковым наблюдениям среднее арифметическое занимаемых ими рангов), получим последовательность соответствующих парам наблюдений рангов $R_i$. Тестовой статистикой будет\n",
    "$$W = \\sum_{i\\in N_r} s_i R_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "test_sample = test_sample[test_sample.PSNR - test_sample.Pearson != 0]\n",
    "test_sample[\"sign\"] = np.sign(test_sample.PSNR - test_sample.Pearson)\n",
    "test_sample[\"absolute_value\"] = np.abs(test_sample.PSNR - test_sample.Pearson)\n",
    "test_sample[\"ranks\"] = rankdata(test_sample.absolute_value)\n",
    "W = np.sum(test_sample.ranks.dot(test_sample.sign))\n",
    "print W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для малых объёмов выборки (7 в нашем случае) распределение случайной величины $W$ при условии выполнения гипотезы $H_0$ может быть подсчитано вручную. Воспользуемся уже готовым критическим значением [отсюда](http://vassarstats.net/textbook/ch12a.html): $W_\\text{крит.} = 24$ для уровня значимости в 5\\%, $W < W_\\text{крит.}$, следовательно, гипотеза об отсутствии различий не может быть отвергнута."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для больших объёмов выборки можно обобщить знания о распределении случайной величины $W$. Так как \n",
    "$$\\mathsf{E}W = 0, \\mathsf{D}W = \\frac{N_r\\left(N_r+1\\right)\\left(2N_r+1\\right)}{6},$$ при увеличении объёма выборки распределение будет стремиться к нормальному с теми же математическим ожиданием и дисперсией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "значение статистики: 0.0164195687821\n"
     ]
    }
   ],
   "source": [
    "res = data.t2 - data.t1\n",
    "splus = len(res[res > 0])\n",
    "t = sp.stats.binom(n, 0.5).sf(splus)\n",
    "print \"значение статистики:\", t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае для всех стандартных уровней значимости гипотеза о незначимости внешнего воздействия между моментами времени $t_1$ и $t_2$ может быть отвергнута."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Критерий Вилкоксона для зависимых выборок\n",
    "Обозначим $R_i$ -- ранг результата $i$-го эксперимента в множестве всех абсолютных значений результатов экспериментов $\\left\\lbrace \\left\\vert r_i\\left(x_{t_1}, x_{t_2}\\right)\\right\\vert\\right\\rbrace_{i=1}^n$. Тогда случайная величина $W = \\min\\left\\lbrace\\sum_{i \\in S_+} R_i, \\sum_{i\\in S_-} R_i\\right\\rbrace$ -- статистика Вилкоксона, для которой можно использовать нормальную аппроксимацию $$t = {W - EW \\over \\sqrt{DW}} = {W - {n(n+1)\\over 4} \\over \\sqrt{n(n+1)(2n+1) \\over 24}} \\overset{\\sim}{\\to} N(0, 1)$$\n",
    "\n",
    "*NB: Интересно, что в исходной [статье](http://sci2s.ugr.es/keel/pdf/algorithm/articulo/wilcoxon1945.pdf) упоминается именно эта статистика $W$, тогда как на [английский Википедии](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#cite_ref-2) используется $W = \\left\\vert\\sum_{i \\in S_+} R_i - \\sum_{i\\in S_-} R_i\\right\\vert$, а на [MachineLearning.ru](http://www.machinelearning.ru/wiki/index.php?title=Критерий_Уилкоксона_для_связных_выборок) $W = \\sum_{i \\in S_+} R_i$. Все статистики показывают, насколько сильно смещение баланса в сторону исходов какого-либо одного типа, но в сравнении с разностью сумм рангов с Вики смысл статистик из оригинальной статьи и с Машинного Обучения кажется гораздо менее явным*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "минимальная сумма рангов: 381.0\n",
      "критическое значение: (-1.959964, 1.959964)\n",
      "значение статистики: -2.47126812672\n"
     ]
    }
   ],
   "source": [
    "# cast to pandas.Series is to ease selection of positive and negative ranks\n",
    "ranks = pd.Series(sp.stats.rankdata(np.abs(res)))\n",
    "W = np.min([ranks[res > 0].sum(), ranks[res < 0].sum()])\n",
    "print \"минимальная сумма рангов:\", W\n",
    "t = (W - n*(n+1) / 4) / np.sqrt(n*(n+1)*(2*n+1)/24)\n",
    "print \"критическое значение: (%f, %f)\"%(-critical_value, critical_value)\n",
    "print \"значение статистики:\", t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартная реализация метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381.0 0.0132839026636\n"
     ]
    }
   ],
   "source": [
    "T, pvalue = sp.stats.wilcoxon(data.t1, data.t2)\n",
    "print T, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, согласно знаковому критерию Вилкоксона медианы выборок из нормального распределения с математическим ожиданием 0 и 2 всё же отличаются, несмотря на большую дисперсию каждого из распределений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- почему одинаковые наблюдения называются ties?\n",
    "- почему [реализация](https://github.com/scipy/scipy/blob/v0.15.1/scipy/stats/stats.py#L4103) ранжированных сумм не содержит чего-то важного (вспомнить, чего!)\n",
    "- почему для signed-rank test из выборки убираются все наблюдения с нулевой разностью, их же может оказаться большинство, что означает незначимость различия, тогда как выбросы из выборки могут дать неконтролируемый результат? Или мы надеемся на разумность аналитика?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Критерии однородности для двух и более выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $k\\geq2$ выборок понятие инверсии не обобщается однозначно, поэтому в исходном виде критерий Вилкоксона не подходит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея $k$ выборок $X^j = \\left\\lbrace x_i^j\\right\\rbrace_{i=1}^{n_j}, j\\in 1:k$, каждая из распределения $\\mathcal{P}_j$, проверим гипотезу о совпадении этих распределений $\\mathcal{P}_1 = \\ldots = \\mathcal{P}_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
